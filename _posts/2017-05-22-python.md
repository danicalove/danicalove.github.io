---
layout: post
title: "学习python 爬虫"
data: 2017-05-22 16:40:11
categories: python 爬虫
tags: python 爬虫
---

* content
{:toc}


感觉很有意思 所以在网上找点教程 了解一下好了









所谓网络抓取，就是把URL地址中指定的网络资源从网络流中读取出来，保存到本地
在python中，使用urllib2这个组件来抓取网页
以urlopen函数的形式提供了一个非常简单的接口
基于python 3.6 开始玩耍

一个最简单的应用
```
import urllib.request
response = urllib.request.urlopen("https://www.douban.com/")
html=response.read()
print(html)
```

就是将访问豆瓣官网时浏览器接收到的代码全部打印出来
HTTP是基于请求和应答机制的，客户端提出请求，服务器提供应答。


HTTP请求时，允许做的另外两件事
## 发送data表单数据
发送一些数据到URL
在HTTP中，这个经常使用的是熟知的POST请求发送
```
import urllib.parse
import urllib.request
 
data= urllib.parse.urlencode({'mailbox' : '1341866751@qq.com',
			'password' : '11'})
data=data.encode('ascii')
with urllib.request.urlopen('https://accounts.douban.com/register',data) as f:
	print(f.read().decode('utf-8'))
```



